# live-agent-project/.env.example
# --- Google AI/Vertex AI Configuration ---
# Choose ONE block (Google AI Studio or Vertex AI)

# Option 1: Google AI Studio (Gemini API Key)
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
GOOGLE_GENAI_USE_VERTEXAI="False"

# Option 2: Vertex AI (using Application Default Credentials)
# GOOGLE_API_KEY="" # Leave empty or remove
# GOOGLE_GENAI_USE_VERTEXAI="True"
# GOOGLE_CLOUD_PROJECT="your-gcp-project-id"
# GOOGLE_CLOUD_LOCATION="us-central1" # e.g., us-central1

# --- Service URLs ---
# The URL where the Specialist Agent's A2A server will run
SPECIALIST_AGENT_A2A_URL="http://localhost:8001"

# --- MCP Server Configuration ---
# How the Specialist Agent will run the MCP Server
# For stdio (simplest for local):
MCP_SERVER_TRANSPORT="stdio"
MCP_SERVER_COMMAND="python" # Command to run python
MCP_SERVER_SCRIPT_PATH="./mcp_servers/stock_mcp_server/server.py" # Relative path from specialist agent perspective

# For HTTP (more complex, requires MCP server to run separately):
# MCP_SERVER_TRANSPORT="http"
# MCP_SERVER_URL="http://localhost:8002/mcp" # Example URL where MCP server listens

# Optional: Logging Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL="INFO"